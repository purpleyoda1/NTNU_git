{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "![](oving2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](task2c_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training stopped after 44 epochs.  \n",
    "Final Train Cross Entropy Loss: 0.08452529520250651  \n",
    "Final Validation Cross Entropy Loss: 0.6049188886493303  \n",
    "Train accuracy: 0.981  \n",
    "Validation accuracy: 0.8329  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "785x64+64x10=50 880"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding improved weights  \n",
    "Training stopped after 28 epochs.  \n",
    "Final Train Cross Entropy Loss: 0.028842773450010798  \n",
    "Final Validation Cross Entropy Loss: 0.2061919544861595  \n",
    "Train accuracy: 0.9969  \n",
    "Validation accuracy: 0.9396   \n",
    "![](task3_weights.png)\n",
    "\n",
    "After improved sigmoid  \n",
    "Training stopped after 26 epochs.  \n",
    "Final Train Cross Entropy Loss: 0.03162280740067008  \n",
    "Final Validation Cross Entropy Loss: 0.21526426614082944  \n",
    "Train accuracy: 0.99595  \n",
    "Validation accuracy: 0.9383  \n",
    "![](task3_weights_sigmoid.png)\n",
    "\n",
    "\n",
    "After momemtum  \n",
    "Training stopped after 20 epochs.  \n",
    "Final Train Cross Entropy Loss: 0.018526288809209552  \n",
    "Final Validation Cross Entropy Loss: 0.23824469455066005  \n",
    "Train accuracy: 0.99855  \n",
    "Validation accuracy: 0.9338  \n",
    "![](task3_weights_sigmoid_momentum.png)\n",
    "  \n",
    "After adding the improved weights both the training and validation accuracy jumps up, however they both dip down again after improved sigmoid, then the train acc goes up again with momentum while vaildation keeps going down. These changes are very small however, and i dont think they are significant. If i did it wrong i feel like the change would be much more drastic.  \n",
    "\n",
    "Also, the convergence speed increases with each added trick. From the base model in task 2 the training time is decreased by more than half. \n",
    "\n",
    "We do however see significant overfitting in all models, evident by the validation accuracy and loss flattening out, while the training acc keep indreasing and the training loss keep decreasing. I think a contributing factor to this is a too strict rule for when the program is allowed to stop training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "![](task3_32_hidden.png)\n",
    "\n",
    "\n",
    "Train accuracy: 0.99645  \n",
    "Validation accuracy: 0.9113  \n",
    "\n",
    "This seems to be underfitting, as the accuracy plateus earlier than what was possible with a higher amount of nodes in the hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "![](task3_128_hidden.png)  \n",
    "  \n",
    "Train accuracy: 1.0  \n",
    "Validation accuracy: 0.9415  \n",
    "\n",
    "This is definitely overfitting, as a training accuracy of 1 is a sign of overfitting, not a perfect model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "![](task4_two_hidden.png)\n",
    "\n",
    "Training stopped after 18 epochs.  \n",
    "Final Train Cross Entropy Loss: 0.02569169268081729  \n",
    "Final Validation Cross Entropy Loss: 0.4148459155837418  \n",
    "Train accuracy: 0.9962  \n",
    "Validation accuracy: 0.8987  \n",
    "\n",
    "\n",
    "In task 3 there was 50,880x2 = 101,760 parameters, times two from task 2 because we also have a momentum for each weight. With an extra hidden layer this increased to (785x64+64x64+64x10)x2 = 109,952 parameters\n",
    "\n",
    "The overfitting seems to be even worse, as the validation accuracy dont just flatten out but actually decrease. I tried to decrease the epochs but the result was still a bit worse than the one layer. I assume this is becuase i have done something wrong, but i dont know what"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "Unfortunately i couldnt get this working on my pc. it just froze up and the vsc crashed. For the next assignment i will be sure to figure how to connect to the cybele pc's and run the code on them, but i unfortunately dont have the time for that now. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('py38': conda)",
   "language": "python",
   "name": "python38164bitpy38condac1f68ca5407a4349b0d7e37676f2fbb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
